{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from lib.lib_utils import Utils \n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import image as mpimg\n",
    "import cv2\n",
    "import torch as Torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trasformazione .xyz to .png \n",
    "Utils.from_xyz_to_png(\n",
    "    Path('/home/gabro/GrapheDetectProject/data.xyz/subset_xyz'), \n",
    "    Path('/home/gabro/GrapheDetectProject/dataset_imm_300'), \n",
    "    100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divisione del dataset in train/ test/\n",
    "#inserire percorso dataset da dividere e percentuale del test \n",
    "Utils.split_dataset('/home/gabro/GrapheDetectProject/data_yolo_new/', 0.2)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model\n",
    "# model = YOLO(\"yolov8n.yaml\")  # build a new model from scratch\n",
    "model = YOLO(\"/home/gabro/GrapheDetectProject/best_100_campioni_new.pt\")  # load a pretrained model (recommended for training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model\n",
    "# model.train(data=\"coco128.yaml\", epochs=3)  # train the model\n",
    "model.train(data=\"config_yolov8.yaml\", epochs=100)  # train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.88 ðŸš€ Python-3.11.3 torch-2.0.0+cu117 CPU\n",
      "YOLOv8n summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "'/content/gdrive/MyDrive/Materiale tirocinio Gabriele/GrapheDefectDetector/google_colab_config.yaml' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m metrics \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mval()  \u001b[39m# evaluate model performance on the validation set\u001b[39;00m\n\u001b[1;32m      2\u001b[0m results \u001b[39m=\u001b[39m model(\u001b[39m\"\u001b[39m\u001b[39m/home/gabro/GrapheDetectProject/b74c9ce2-graphene_218641_bonds.png\u001b[39m\u001b[39m\"\u001b[39m)  \u001b[39m# predict on an image\u001b[39;00m\n\u001b[1;32m      3\u001b[0m success \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mexport(\u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39monnx\u001b[39m\u001b[39m\"\u001b[39m)  \u001b[39m# export the model to ONNX format\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/graphe-env/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/graphe-env/lib/python3.11/site-packages/ultralytics/yolo/engine/model.py:301\u001b[0m, in \u001b[0;36mYOLO.val\u001b[0;34m(self, data, **kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m args\u001b[39m.\u001b[39mimgsz \u001b[39m=\u001b[39m check_imgsz(args\u001b[39m.\u001b[39mimgsz, max_dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    300\u001b[0m validator \u001b[39m=\u001b[39m TASK_MAP[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask][\u001b[39m2\u001b[39m](args\u001b[39m=\u001b[39margs, _callbacks\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks)\n\u001b[0;32m--> 301\u001b[0m validator(model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel)\n\u001b[1;32m    302\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics \u001b[39m=\u001b[39m validator\u001b[39m.\u001b[39mmetrics\n\u001b[1;32m    304\u001b[0m \u001b[39mreturn\u001b[39;00m validator\u001b[39m.\u001b[39mmetrics\n",
      "File \u001b[0;32m~/anaconda3/envs/graphe-env/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/graphe-env/lib/python3.11/site-packages/ultralytics/yolo/engine/validator.py:125\u001b[0m, in \u001b[0;36mBaseValidator.__call__\u001b[0;34m(self, trainer, model)\u001b[0m\n\u001b[1;32m    122\u001b[0m         LOGGER\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mForcing batch=1 square inference (1,3,\u001b[39m\u001b[39m{\u001b[39;00mimgsz\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m{\u001b[39;00mimgsz\u001b[39m}\u001b[39;00m\u001b[39m) for non-PyTorch models\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    124\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdata, \u001b[39mstr\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m.yaml\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 125\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m check_det_dataset(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49mdata)\n\u001b[1;32m    126\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mtask \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mclassify\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    127\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m check_cls_dataset(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdata)\n",
      "File \u001b[0;32m~/anaconda3/envs/graphe-env/lib/python3.11/site-packages/ultralytics/yolo/data/utils.py:195\u001b[0m, in \u001b[0;36mcheck_det_dataset\u001b[0;34m(dataset, autodownload)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_det_dataset\u001b[39m(dataset, autodownload\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    194\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Download, check and/or unzip dataset if not found locally.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 195\u001b[0m     data \u001b[39m=\u001b[39m check_file(dataset)\n\u001b[1;32m    197\u001b[0m     \u001b[39m# Download (optional)\u001b[39;00m\n\u001b[1;32m    198\u001b[0m     extract_dir \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/graphe-env/lib/python3.11/site-packages/ultralytics/yolo/utils/checks.py:292\u001b[0m, in \u001b[0;36mcheck_file\u001b[0;34m(file, suffix, download, hard)\u001b[0m\n\u001b[1;32m    290\u001b[0m     files\u001b[39m.\u001b[39mextend(glob\u001b[39m.\u001b[39mglob(\u001b[39mstr\u001b[39m(ROOT \u001b[39m/\u001b[39m d \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39m**\u001b[39m\u001b[39m'\u001b[39m \u001b[39m/\u001b[39m file), recursive\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))  \u001b[39m# find file\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m files \u001b[39mand\u001b[39;00m hard:\n\u001b[0;32m--> 292\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m does not exist\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(files) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m hard:\n\u001b[1;32m    294\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMultiple files match \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, specify exact path: \u001b[39m\u001b[39m{\u001b[39;00mfiles\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: '/content/gdrive/MyDrive/Materiale tirocinio Gabriele/GrapheDefectDetector/google_colab_config.yaml' does not exist"
     ]
    }
   ],
   "source": [
    "metrics = model.val()  # evaluate model performance on the validation set\n",
    "results = model(\"/home/gabro/GrapheDetectProject/b74c9ce2-graphene_218641_bonds.png\")  # predict on an image\n",
    "success = model.export(format=\"onnx\")  # export the model to ONNX format"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inferenza e trasformazione boxes in immagini singole "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/gabro/GrapheDetectProject/b74c9ce2-graphene_218641_bonds.png: 640x640 2 defects, 298.8ms\n",
      "Speed: 7.9ms preprocess, 298.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method size of Tensor object at 0x7fac63d53de0>\n",
      "tensor([[ 4.3943, 18.4342, 34.3378, 50.7019]])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m box \u001b[39min\u001b[39;00m boxes:\n\u001b[1;32m     10\u001b[0m     \u001b[39m#devo trasformare xy (alto sx), xy (alto dx) in [start_row:end_row, start_col:end_col]\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[39mprint\u001b[39m(boxes[index]\u001b[39m.\u001b[39mxyxy)    \u001b[39m#posizione angolo in alto a sx e in basso a dx in pixel\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     array \u001b[39m=\u001b[39m Torch\u001b[39m.\u001b[39mTensor\u001b[39m.\u001b[39mnumpy(boxes[index]\u001b[39m.\u001b[39mxyxy)\n\u001b[1;32m     13\u001b[0m     \u001b[39m# print(array.size)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     x1 \u001b[39m=\u001b[39m math\u001b[39m.\u001b[39mceil(array[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Torch' is not defined"
     ]
    }
   ],
   "source": [
    "pathImmProva = \"/home/gabro/GrapheDetectProject/b74c9ce2-graphene_218641_bonds.png\"\n",
    "results = model(pathImmProva)  # predict on an image\n",
    "\n",
    "boxes = results[0].boxes\n",
    "index = 0\n",
    "print(boxes.data.size)\n",
    "# for box in boxes.data:\n",
    "#     print(box.xyxy)\n",
    "for box in boxes:\n",
    "    #devo trasformare xy (alto sx), xy (alto dx) in [start_row:end_row, start_col:end_col]\n",
    "    print(boxes[index].xyxy)    #posizione angolo in alto a sx e in basso a dx in pixel\n",
    "    array = Torch.Tensor.numpy(boxes[index].xyxy)\n",
    "    # print(array.size)\n",
    "    x1 = math.ceil(array[0,0])\n",
    "    y1 = math.ceil(array[0,1])\n",
    "    x2 = math.floor(array[0,2])\n",
    "    y2 = math.floor(array[0,3])\n",
    "\n",
    "    # res_plotted = results[0].plot(labels = False, line_width = 1)\n",
    "    # plt.imshow(res_plotted)\n",
    "    # plt.show()\n",
    "    # cv2.imshow(\"result\", res_plotted)\n",
    "\n",
    "    #crop difetto\n",
    "    img = cv2.imread(pathImmProva)\n",
    "    print(img.shape) # Print image shape\n",
    "    # cv2.imshow(\"original\", img)\n",
    "    \n",
    "    # Cropping an image\n",
    "    cropped_image = img[y1:y2, x1:x2] #img[start_row:end_row, start_col:end_col]\n",
    "\n",
    "    # Display cropped image\n",
    "    # cv2.imshow(\"cropped\", cropped_image)\n",
    "\n",
    "    nameCropped = pathImmProva.removesuffix('.png') + \"_cropped_box_\" + str(index)+ \".png\"\n",
    "    # Save the cropped image\n",
    "    cv2.imwrite(nameCropped, cropped_image)\n",
    "    \n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "\n",
    "    index = index+1\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphe-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
